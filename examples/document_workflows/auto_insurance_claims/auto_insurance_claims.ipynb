{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a65d3850-3ddb-4db3-87fe-fa7d92e6c55b",
      "metadata": {
        "id": "a65d3850-3ddb-4db3-87fe-fa7d92e6c55b"
      },
      "source": [
        "# Auto Insurance Claim Processing Workflow\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/run-llama/llamacloud-demo/blob/main/examples/document_workflows/auto_insurance_claims/auto_insurance_claims.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n",
        "This tutorial demonstrates how to build an agentic workflow that can parse auto insurance claims, retrieve and apply relevant policy guidelines, and produce a structured recommendation on whether and how to settle the claim. The workflow follows a similar pattern to the patient case summary workflow, but adapted for insurance data.\n",
        "\n",
        "![](https://github.com/run-llama/llamacloud-demo/blob/main/examples/document_workflows/auto_insurance_claims/auto_insurance_claims.png?raw=1)\n",
        "\n",
        "The workflow will:\n",
        "\n",
        "1. Parse the Claim Document: Extract key fields (claim number, date of loss, claimant name, policy number, loss description, estimated damage costs).\n",
        "2. Index/Load Insurance Policy Documents: Either via LlamaCloud or another indexing solution.\n",
        "3. Generate Relevant Queries: Given the claim details, construct vector-based queries to retrieve the appropriate coverage sections from the policy index.\n",
        "3. Match Conditions Against Policy: Use LLM reasoning to determine if the claim is covered, what deductible applies, whether special endorsements are triggered, and what the recommended settlement amount should be.\n",
        "4. Produce a Structured Output: Summarize the final recommended settlement and conditions for payment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "87c5f0d7-c884-475a-88ff-4b7057bb91a6",
      "metadata": {
        "id": "87c5f0d7-c884-475a-88ff-4b7057bb91a6",
        "outputId": "d62bc80d-975b-4a2c-e092-121699fc66de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-index\n",
            "  Downloading llama_index-0.12.8-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting llama-index-indices-managed-llama-cloud\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.6.3-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting llama-cloud\n",
            "  Downloading llama_cloud-0.1.6-py3-none-any.whl.metadata (814 bytes)\n",
            "Collecting llama-parse\n",
            "  Downloading llama_parse-0.5.18-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting llama-index-agent-openai<0.5.0,>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_agent_openai-0.4.1-py3-none-any.whl.metadata (726 bytes)\n",
            "Collecting llama-index-cli<0.5.0,>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_cli-0.4.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting llama-index-core<0.13.0,>=0.12.8 (from llama-index)\n",
            "  Downloading llama_index_core-0.12.8-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting llama-index-embeddings-openai<0.4.0,>=0.3.0 (from llama-index)\n",
            "  Downloading llama_index_embeddings_openai-0.3.1-py3-none-any.whl.metadata (684 bytes)\n",
            "Collecting llama-index-llms-openai<0.4.0,>=0.3.0 (from llama-index)\n",
            "  Downloading llama_index_llms_openai-0.3.12-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-index-multi-modal-llms-openai<0.5.0,>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_multi_modal_llms_openai-0.4.1-py3-none-any.whl.metadata (726 bytes)\n",
            "Collecting llama-index-program-openai<0.4.0,>=0.3.0 (from llama-index)\n",
            "  Downloading llama_index_program_openai-0.3.1-py3-none-any.whl.metadata (764 bytes)\n",
            "Collecting llama-index-question-gen-openai<0.4.0,>=0.3.0 (from llama-index)\n",
            "  Downloading llama_index_question_gen_openai-0.3.0-py3-none-any.whl.metadata (783 bytes)\n",
            "Collecting llama-index-readers-file<0.5.0,>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_readers_file-0.4.1-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting llama-index-readers-llama-parse>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_readers_llama_parse-0.4.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index) (3.9.1)\n",
            "Requirement already satisfied: httpx>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from llama-cloud) (0.28.1)\n",
            "Requirement already satisfied: pydantic>=1.10 in /usr/local/lib/python3.10/dist-packages (from llama-cloud) (2.10.3)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.7 in /usr/local/lib/python3.10/dist-packages (from llama-parse) (8.1.7)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.20.0->llama-cloud) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.20.0->llama-cloud) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.20.0->llama-cloud) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.20.0->llama-cloud) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.20.0->llama-cloud) (0.14.0)\n",
            "Requirement already satisfied: openai>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.57.4)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.8->llama-index) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index) (3.11.10)\n",
            "Collecting dataclasses-json (from llama-index-core<0.13.0,>=0.12.8->llama-index)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index) (1.2.15)\n",
            "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.13.0,>=0.12.8->llama-index)\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from llama-index-core<0.13.0,>=0.12.8->llama-index)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index) (2024.10.0)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index) (3.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index) (1.26.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index) (11.0.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index) (9.0.0)\n",
            "Collecting tiktoken>=0.3.3 (from llama-index-core<0.13.0,>=0.12.8->llama-index)\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index) (4.12.2)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.13.0,>=0.12.8->llama-index)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index) (1.17.0)\n",
            "Collecting openai>=1.14.0 (from llama-index-agent-openai<0.5.0,>=0.4.0->llama-index)\n",
            "  Downloading openai-1.58.1-py3-none-any.whl.metadata (27 kB)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (4.12.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.2.2)\n",
            "Collecting pypdf<6.0.0,>=5.1.0 (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index)\n",
            "  Downloading pypdf-5.1.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index)\n",
            "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index) (2024.11.6)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llama-cloud) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llama-cloud) (2.27.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.8->llama-index) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.8->llama-index) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.8->llama-index) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.8->llama-index) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.8->llama-index) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.8->llama-index) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.8->llama-index) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.8->llama-index) (1.18.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.6)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.20.0->llama-cloud) (1.2.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.8->llama-index) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.8->llama-index) (2.2.3)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.8->llama-index) (3.1.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.8->llama-index)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.13.0,>=0.12.8->llama-index)\n",
            "  Downloading marshmallow-3.23.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2024.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.8->llama-index) (24.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (1.17.0)\n",
            "Downloading llama_index-0.12.8-py3-none-any.whl (6.8 kB)\n",
            "Downloading llama_index_indices_managed_llama_cloud-0.6.3-py3-none-any.whl (11 kB)\n",
            "Downloading llama_cloud-0.1.6-py3-none-any.whl (195 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.8/195.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_parse-0.5.18-py3-none-any.whl (15 kB)\n",
            "Downloading llama_index_agent_openai-0.4.1-py3-none-any.whl (13 kB)\n",
            "Downloading llama_index_cli-0.4.0-py3-none-any.whl (27 kB)\n",
            "Downloading llama_index_core-0.12.8-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_embeddings_openai-0.3.1-py3-none-any.whl (6.2 kB)\n",
            "Downloading llama_index_llms_openai-0.3.12-py3-none-any.whl (14 kB)\n",
            "Downloading llama_index_multi_modal_llms_openai-0.4.1-py3-none-any.whl (5.8 kB)\n",
            "Downloading llama_index_program_openai-0.3.1-py3-none-any.whl (5.3 kB)\n",
            "Downloading llama_index_question_gen_openai-0.3.0-py3-none-any.whl (2.9 kB)\n",
            "Downloading llama_index_readers_file-0.4.1-py3-none-any.whl (38 kB)\n",
            "Downloading llama_index_readers_llama_parse-0.4.0-py3-none-any.whl (2.5 kB)\n",
            "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading openai-1.58.1-py3-none-any.whl (454 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.3/454.3 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf-5.1.0-py3-none-any.whl (297 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
            "Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading marshmallow-3.23.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: striprtf, filetype, dirtyjson, pypdf, mypy-extensions, marshmallow, typing-inspect, tiktoken, openai, llama-cloud, dataclasses-json, llama-index-core, llama-parse, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.57.4\n",
            "    Uninstalling openai-1.57.4:\n",
            "      Successfully uninstalled openai-1.57.4\n",
            "Successfully installed dataclasses-json-0.6.7 dirtyjson-1.0.8 filetype-1.2.0 llama-cloud-0.1.6 llama-index-0.12.8 llama-index-agent-openai-0.4.1 llama-index-cli-0.4.0 llama-index-core-0.12.8 llama-index-embeddings-openai-0.3.1 llama-index-indices-managed-llama-cloud-0.6.3 llama-index-llms-openai-0.3.12 llama-index-multi-modal-llms-openai-0.4.1 llama-index-program-openai-0.3.1 llama-index-question-gen-openai-0.3.0 llama-index-readers-file-0.4.1 llama-index-readers-llama-parse-0.4.0 llama-parse-0.5.18 marshmallow-3.23.2 mypy-extensions-1.0.0 openai-1.58.1 pypdf-5.1.0 striprtf-0.0.26 tiktoken-0.8.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install llama-index llama-index-indices-managed-llama-cloud llama-cloud llama-parse"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e9caaf2-dc67-4da9-a3b5-2bc5c3eb7df7",
      "metadata": {
        "id": "2e9caaf2-dc67-4da9-a3b5-2bc5c3eb7df7"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a342d56d-28c0-43dc-aa57-817b96448efa",
      "metadata": {
        "id": "a342d56d-28c0-43dc-aa57-817b96448efa"
      },
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "from typing import List, Optional\n",
        "from pydantic import BaseModel, Field"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19df0d40-ce23-4bdd-9fb1-0249d4995fba",
      "metadata": {
        "id": "19df0d40-ce23-4bdd-9fb1-0249d4995fba"
      },
      "source": [
        "### Define Schemas\n",
        "We define schemas for our claim data and final recommendation. Similar to the patient workflow, we’ll have:\n",
        "\n",
        "`ClaimInfo`: Captures details from the claim document.\n",
        "`PolicyCondition`: Represents extracted or relevant policy conditions.\n",
        "`ClaimEvaluation`: Represents the outcome after evaluating the claim against the policy."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bdbe1b68-c1f5-402e-b5d7-319346d9010b",
      "metadata": {
        "id": "bdbe1b68-c1f5-402e-b5d7-319346d9010b"
      },
      "source": [
        "#### ClaimInfo Schema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72984520-f81c-498c-9a2e-92b6696a34e2",
      "metadata": {
        "id": "72984520-f81c-498c-9a2e-92b6696a34e2"
      },
      "outputs": [],
      "source": [
        "class ClaimInfo(BaseModel):\n",
        "    \"\"\"Extracted Insurance claim information.\"\"\"\n",
        "    claim_number: str\n",
        "    policy_number: str\n",
        "    claimant_name: str\n",
        "    date_of_loss: str\n",
        "    loss_description: str\n",
        "    estimated_repair_cost: float\n",
        "    vehicle_details: Optional[str] = None"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c99b99f6-70bb-433a-ba7b-b42878efb6d1",
      "metadata": {
        "id": "c99b99f6-70bb-433a-ba7b-b42878efb6d1"
      },
      "source": [
        "#### PolicyCondition and PolicyQueries\n",
        "\n",
        "We will also define a schema for generating guideline (in this case, coverage guideline) queries and for storing recommendations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc5596da-7ee3-439c-9bc2-cbc704d0d7cf",
      "metadata": {
        "id": "bc5596da-7ee3-439c-9bc2-cbc704d0d7cf"
      },
      "outputs": [],
      "source": [
        "class PolicyQueries(BaseModel):\n",
        "    queries: List[str] = Field(\n",
        "        default_factory=list,\n",
        "        description=\"A list of query strings to retrieve relevant policy sections.\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15966fe1-0bbf-4ad4-b92c-43abf3b49b4d",
      "metadata": {
        "id": "15966fe1-0bbf-4ad4-b92c-43abf3b49b4d"
      },
      "source": [
        "#### Guideline/Policy Recommendation Schema\n",
        "\n",
        "We want to produce a structured recommendation about claim coverage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "910adebd-7289-4193-b7b9-af398ba542d1",
      "metadata": {
        "id": "910adebd-7289-4193-b7b9-af398ba542d1"
      },
      "outputs": [],
      "source": [
        "class PolicyRecommendation(BaseModel):\n",
        "    \"\"\"Policy recommendation regarding a given claim.\"\"\"\n",
        "    policy_section: str = Field(..., description=\"The policy section or clause that applies.\")\n",
        "    recommendation_summary: str = Field(..., description=\"A concise summary of coverage determination.\")\n",
        "    deductible: Optional[float] = Field(None, description=\"The applicable deductible amount.\")\n",
        "    settlement_amount: Optional[float] = Field(None, description=\"Recommended settlement payout.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "324f98a5-f3a8-417f-80f3-c742078c0e39",
      "metadata": {
        "id": "324f98a5-f3a8-417f-80f3-c742078c0e39"
      },
      "source": [
        "#### Final Claim Decision Schema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b1121f9-0831-49fc-ba8f-3ccdcb2423ad",
      "metadata": {
        "id": "3b1121f9-0831-49fc-ba8f-3ccdcb2423ad"
      },
      "outputs": [],
      "source": [
        "class ClaimDecision(BaseModel):\n",
        "    claim_number: str\n",
        "    covered: bool\n",
        "    deductible: float\n",
        "    recommended_payout: float\n",
        "    notes: Optional[str] = None"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba75f272-97ff-4c88-982a-06edaf6232da",
      "metadata": {
        "id": "ba75f272-97ff-4c88-982a-06edaf6232da"
      },
      "source": [
        "### Loading the Claim Document\n",
        "\n",
        "In a real scenario, we’d have a PDF or text form with claim details. For this demonstration, we assume we have a JSON file containing claim data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46e99884-4516-4f51-8c12-2c280caa6f5b",
      "metadata": {
        "id": "46e99884-4516-4f51-8c12-2c280caa6f5b"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "def parse_claim(file_path: str) -> ClaimInfo:\n",
        "    with open(file_path, \"r\") as f:\n",
        "        data = json.load(f)\n",
        "    # Validate and return\n",
        "    return ClaimInfo.model_validate(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d530925c-056b-4b50-936f-8c05b2e7aaaa",
      "metadata": {
        "id": "d530925c-056b-4b50-936f-8c05b2e7aaaa"
      },
      "source": [
        "Example Claim Input (john.json):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ce4654e-ff6e-46e9-ac9b-a498d79db6d6",
      "metadata": {
        "id": "0ce4654e-ff6e-46e9-ac9b-a498d79db6d6",
        "outputId": "9a2ebf95-ac2d-4006-d954-91d1e5f677e4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'claim_number': 'CLAIM-0001',\n",
              " 'policy_number': 'POLICY-ABC123',\n",
              " 'claimant_name': 'John Smith',\n",
              " 'date_of_loss': '2024-04-10',\n",
              " 'loss_description': 'While delivering pizzas, collided with a parked car, causing damage to the parked car’s door.',\n",
              " 'estimated_repair_cost': 1500.0,\n",
              " 'vehicle_details': '2022 Honda Civic'}"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "claim_info = parse_claim(\"data/john.json\")\n",
        "claim_info.dict()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "475d17e7-5076-4903-b29c-de99f1eb2497",
      "metadata": {
        "id": "475d17e7-5076-4903-b29c-de99f1eb2497"
      },
      "source": [
        "(We assume this works and shows the parsed claim data.)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfc43f0f-1194-4859-98d9-c9903f64754e",
      "metadata": {
        "id": "dfc43f0f-1194-4859-98d9-c9903f64754e"
      },
      "source": [
        "### Indexing Policy Documents\n",
        "\n",
        "We will be indexing a sample [California Personal Automobile Policy](https://nationalgeneral.com/forms_catalog/CAIP400_03012006_CA.pdf) which we will validate the claims against.\n",
        "\n",
        "Make sure to download the docment and upload it to [LlamaCloud](https://cloud.llamaindex.ai/). If you don't have access yet, you can use our open-source VectorStoreIndex."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34f692f8-5ebc-4a0c-af2c-0bf08bd44562",
      "metadata": {
        "id": "34f692f8-5ebc-4a0c-af2c-0bf08bd44562"
      },
      "outputs": [],
      "source": [
        "from llama_index.indices.managed.llama_cloud import LlamaCloudIndex\n",
        "\n",
        "index = LlamaCloudIndex(\n",
        "    name=\"auto_insurance_policies_0\",\n",
        "    project_name=\"llamacloud_demo\",\n",
        "    # organization_id=\"...\",\n",
        "    # api_key=\"...\"\n",
        ")\n",
        "\n",
        "retriever = index.as_retriever(rerank_top_n=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "862b0614-ef9b-4a8f-8a80-7b29fdb70dc1",
      "metadata": {
        "id": "862b0614-ef9b-4a8f-8a80-7b29fdb70dc1"
      },
      "source": [
        "### Indexing Per-User Declarations Documents\n",
        "\n",
        "Besides the general auto-insurance policy, we need a separate index to store the per-user declarations pages. These include specific details for each policy holder. They need to be filtered according to the right policy number during retrieval.\n",
        "\n",
        "The declarations are stored in the `data` folder. In LlamaCloud, drag and drop the markdown files (not the JSON files) into a new LlamaCloud index. We will also attach the policy number as metadata."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fc22fa0-e658-4739-ba3d-45e7a03a26bf",
      "metadata": {
        "id": "9fc22fa0-e658-4739-ba3d-45e7a03a26bf"
      },
      "outputs": [],
      "source": [
        "from llama_index.indices.managed.llama_cloud import LlamaCloudIndex\n",
        "import os\n",
        "\n",
        "declarations_index = LlamaCloudIndex(\n",
        "    name=\"auto_insurance_declarations_0\",\n",
        "    project_name=\"llamacloud_demo\",\n",
        "    # organization_id=\"...\",\n",
        "    # api_key=\"...\"\n",
        ")\n",
        "\n",
        "from llama_cloud.client import LlamaCloud\n",
        "\n",
        "client = LlamaCloud(\n",
        "    base_url=\"https://api.cloud.llamaindex.ai\",\n",
        "    token=os.environ[\"LLAMA_CLOUD_API_KEY\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b843423c-014a-41c8-ac0a-c54b6527d51a",
      "metadata": {
        "id": "b843423c-014a-41c8-ac0a-c54b6527d51a"
      },
      "source": [
        "We use the API endpoint to load custom documents into the index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b70cb8e-3f32-4a7d-96c4-f865208ea575",
      "metadata": {
        "id": "5b70cb8e-3f32-4a7d-96c4-f865208ea575",
        "outputId": "7728c3ff-9ef3-4471-aba2-0dab07bbad7a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'file_size': 1410,\n",
              " 'last_modified_at': '2024-12-15T20:44:48',\n",
              " 'file_path': 'john-declarations.md',\n",
              " 'file_name': 'john-declarations.md',\n",
              " 'external_file_id': 'john-declarations.md',\n",
              " 'pipeline_id': 'daaa2430-6e34-46d9-9948-5ed80f677a9b',\n",
              " 'policy_number': 'POLICY-ABC123'}"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# TODO: make this function not hidden\n",
        "declarations_pipeline_id = declarations_index._get_pipeline_id()\n",
        "declarations_project_id = declarations_index._get_project_id()\n",
        "\n",
        "person_policy_map = {}\n",
        "for p in [\"alice\", \"john\"]:\n",
        "    claim_info = parse_claim(f\"data/{p}.json\")\n",
        "    policy_num = claim_info.policy_number\n",
        "    person_policy_map[f\"{p}-declarations.md\"] = policy_num\n",
        "\n",
        "pipeline_docs = client.pipelines.list_pipeline_documents(declarations_pipeline_id)\n",
        "for doc in pipeline_docs:\n",
        "    doc.metadata[\"policy_number\"] = person_policy_map[doc.metadata[\"file_name\"]]\n",
        "upserted_docs = client.pipelines.upsert_batch_pipeline_documents(declarations_pipeline_id, request=pipeline_docs)\n",
        "upserted_docs[0].metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50713e96-9a5e-495f-a777-c4388bb5e230",
      "metadata": {
        "id": "50713e96-9a5e-495f-a777-c4388bb5e230"
      },
      "source": [
        "Check that it's been set appropriately"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29898fa6-80ed-4442-9c00-86f0b3c8606b",
      "metadata": {
        "id": "29898fa6-80ed-4442-9c00-86f0b3c8606b",
        "outputId": "edc0526a-711e-417e-d0a1-9315fe3047e4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'file_size': 1453,\n",
              " 'last_modified_at': '2024-12-15T20:44:48',\n",
              " 'file_path': 'alice-declarations.md',\n",
              " 'file_name': 'alice-declarations.md',\n",
              " 'external_file_id': 'alice-declarations.md',\n",
              " 'pipeline_id': 'daaa2430-6e34-46d9-9948-5ed80f677a9b',\n",
              " 'policy_number': 'POLICY-XYZ789'}"
            ]
          },
          "execution_count": 112,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipeline_docs = client.pipelines.list_pipeline_documents(declarations_pipeline_id)\n",
        "len(pipeline_docs)\n",
        "# inspect the first document\n",
        "pipeline_docs[0].metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4e94aed-663c-4f43-9249-a4a8666350ac",
      "metadata": {
        "id": "e4e94aed-663c-4f43-9249-a4a8666350ac"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.vector_stores.types import (\n",
        "    MetadataInfo,\n",
        "    MetadataFilters,\n",
        ")\n",
        "\n",
        "def get_declarations_docs(policy_number: str, top_k: int = 1):\n",
        "    \"\"\"Get declarations retriever.\"\"\"\n",
        "    # build retriever and query engine\n",
        "    filters = MetadataFilters.from_dicts([\n",
        "        {\"key\": \"policy_number\", \"value\": policy_number}\n",
        "    ])\n",
        "    retriever = declarations_index.as_retriever(\n",
        "        # TODO: do file-level retrieval\n",
        "        # retrieval_mode=\"files_via_metadata\",\n",
        "        rerank_top_n=top_k,\n",
        "        filters=filters\n",
        "    )\n",
        "    # semantic query matters less here\n",
        "    return retriever.retrieve(f\"declarations page for {policy_number}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f624c5fc-20e9-4d82-9a6d-0ff4393b3e15",
      "metadata": {
        "scrolled": true,
        "id": "f624c5fc-20e9-4d82-9a6d-0ff4393b3e15",
        "outputId": "827b588d-46e2-4e79-b1b0-7570ed1f7db5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n",
            "file_size: 1410\n",
            "last_modified_at: 2024-12-15T20:44:48\n",
            "file_path: john-declarations.md\n",
            "file_name: john-declarations.md\n",
            "external_file_id: john-declarations.md\n",
            "pipeline_id: daaa2430-6e34-46d9-9948-5ed80f677a9b\n",
            "policy_number: POLICY-ABC123\n",
            "document_1_page_label: 1\n",
            "\n",
            "# CALIFORNIA PERSONAL AUTO POLICY DECLARATIONS PAGE\n",
            "**Policy Number:** CAP-ABC123-01  \n",
            "**Policy Period:** 01/01/2024 to 07/01/2024  \n",
            "(12:01 A.M. standard time at the address below)\n",
            "\n",
            "**Named Insured:**  \n",
            "John Smith  \n",
            "456 Delivery Lane  \n",
            "San Francisco, CA 94112\n",
            "\n",
            "**Vehicle Information:**  \n",
            "Vehicle: 2022 Honda Civic LX Sedan  \n",
            "VIN: 2HGFE2F54NH123456  \n",
            "Principal Operator: John Smith  \n",
            "Usage: Personal\n",
            "\n",
            "**Coverages and Premiums:**\n",
            "\n",
            "- Bodily Injury Liability: $100,000/$300,000 [$450]\n",
            "- Property Damage Liability: $50,000 [$295]\n",
            "- Medical Payments: $5,000 [$80]\n",
            "- Uninsured/Underinsured Motorist: $100,000/$300,000 [$115]\n",
            "- Collision Coverage: $500 deductible [$425]\n",
            "- Other Than Collision: $250 deductible [$210]\n",
            "- Rental Reimbursement: $30/day, max $900 [$30]\n",
            "- Towing and Labor: $75 per disablement [$20]\n",
            "\n",
            "**Total Semi-Annual Premium:** $1,625\n",
            "\n",
            "**Discounts Applied:**\n",
            "- Safe Driver Discount\n",
            "- Anti-theft Device Discount\n",
            "- Automatic Payment Discount\n",
            "\n",
            "**Forms and Endorsements:**\n",
            "- CAIP400 (03012006) - Personal Auto Policy\n",
            "- CA401 - Towing and Labor Costs Coverage\n",
            "- CA405 - Rental Reimbursement Coverage\n",
            "- CA410 - Pollution Exclusion\n",
            "\n",
            "**Loss Payee/Additional Interest:**\n",
            "Honda Financial Services  \n",
            "Account #: HFS-123456789  \n",
            "P.O. Box 44444  \n",
            "Dallas, TX 75202\n",
            "\n",
            "**Special Provisions:**\n",
            "This is a summary of your coverages. Please refer to your policy for complete details of coverage, conditions, and exclusions.\n"
          ]
        }
      ],
      "source": [
        "# try it out\n",
        "docs = get_declarations_docs(\"POLICY-ABC123\")\n",
        "print(len(docs))\n",
        "print(docs[0].get_content(metadata_mode=\"all\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e8d6bb7-d317-4ca0-97ff-57c8785192cf",
      "metadata": {
        "id": "0e8d6bb7-d317-4ca0-97ff-57c8785192cf"
      },
      "source": [
        "### Prompts"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cbaef9c2-9606-48c4-a73d-ae08e124dd82",
      "metadata": {
        "id": "cbaef9c2-9606-48c4-a73d-ae08e124dd82"
      },
      "source": [
        "#### Generating Policy Queries\n",
        "\n",
        "We prompt the LLM to generate queries for retrieving relevant policy sections. For example:\n",
        "\n",
        "- Coverage conditions for collision damage.\n",
        "- Deductible conditions.\n",
        "- Any special endorsements for rental coverage or waived deductible scenarios."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7225d0d3-2354-469a-a55f-ace64fb4ff73",
      "metadata": {
        "id": "7225d0d3-2354-469a-a55f-ace64fb4ff73"
      },
      "outputs": [],
      "source": [
        "GENERATE_POLICY_QUERIES_PROMPT = \"\"\"\\\n",
        "You are an assistant tasked with determining what insurance policy sections to consult for a given auto claim.\n",
        "\n",
        "**Instructions:**\n",
        "1. Review the claim data, including the type of loss (rear-end collision), estimated repair cost, and policy number.\n",
        "2. Identify what aspects of the policy we need:\n",
        "   - Collision coverage conditions\n",
        "   - Deductible application\n",
        "   - Any special endorsements related to rear-end collisions or no-fault scenarios\n",
        "3. Produce 3-5 queries that can be used against a vector index of insurance policies to find relevant clauses.\n",
        "\n",
        "Claim Data:\n",
        "{claim_info}\n",
        "\n",
        "Return a JSON object matching the PolicyQueries schema.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2cb45e18-6234-4345-8d55-80ff9d35d423",
      "metadata": {
        "id": "2cb45e18-6234-4345-8d55-80ff9d35d423"
      },
      "source": [
        "#### Policy Recommendation Prompt\n",
        "Once we have queries, we’ll run them against the policy index, retrieve the text, and feed it back to the LLM to produce a PolicyRecommendation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22f08099-0477-47cc-9a5f-ca696629a43f",
      "metadata": {
        "id": "22f08099-0477-47cc-9a5f-ca696629a43f"
      },
      "outputs": [],
      "source": [
        "POLICY_RECOMMENDATION_PROMPT = \"\"\"\\\n",
        "Given the retrieved policy sections for this claim, determine:\n",
        "- If the collision is covered\n",
        "- The applicable deductible\n",
        "- Recommended settlement amount (e.g., cost minus deductible)\n",
        "- Which policy section applies\n",
        "\n",
        "Claim Info:\n",
        "{claim_info}\n",
        "\n",
        "Policy Text:\n",
        "{policy_text}\n",
        "\n",
        "Return a JSON object matching PolicyRecommendation schema.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ff8eebc-c00e-4499-ad5d-2d7843786eba",
      "metadata": {
        "id": "0ff8eebc-c00e-4499-ad5d-2d7843786eba"
      },
      "source": [
        "## Auto Insurance Claim Processing Workflow\n",
        "\n",
        "This workflow takes an auto insurance claim, generates queries to retrieve relevant policy sections, evaluates coverage and deductibles, and produces a final claim decision with recommended payout."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b803856-630c-497c-9142-bd5aeb9efa5d",
      "metadata": {
        "id": "8b803856-630c-497c-9142-bd5aeb9efa5d"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.workflow import (\n",
        "    Event,\n",
        "    StartEvent,\n",
        "    StopEvent,\n",
        "    Context,\n",
        "    Workflow,\n",
        "    step\n",
        ")\n",
        "from llama_index.core.llms import LLM\n",
        "from llama_index.core.prompts import ChatPromptTemplate\n",
        "from llama_index.llms.openai import OpenAI\n",
        "from llama_index.core.retrievers import BaseRetriever\n",
        "\n",
        "class ClaimInfoEvent(Event):\n",
        "    claim_info: ClaimInfo\n",
        "\n",
        "class PolicyQueryEvent(Event):\n",
        "    queries: PolicyQueries\n",
        "\n",
        "class PolicyMatchedEvent(Event):\n",
        "    policy_text: str\n",
        "\n",
        "class RecommendationEvent(Event):\n",
        "    recommendation: PolicyRecommendation\n",
        "\n",
        "class DecisionEvent(Event):\n",
        "    decision: ClaimDecision\n",
        "\n",
        "class LogEvent(Event):\n",
        "    msg: str\n",
        "    delta: bool = False\n",
        "\n",
        "\n",
        "def parse_claim(file_path: str) -> ClaimInfo:\n",
        "    import json\n",
        "    with open(file_path, \"r\") as f:\n",
        "        data = json.load(f)\n",
        "    return ClaimInfo.model_validate(data)  # replace \"ClaimInfo\".model_validate with actual ClaimInfo class method\n",
        "\n",
        "class AutoInsuranceWorkflow(Workflow):\n",
        "    def __init__(\n",
        "        self,\n",
        "        policy_retriever: BaseRetriever,\n",
        "        llm: LLM | None = None,\n",
        "        output_dir: str = \"data_out\",\n",
        "        **kwargs\n",
        "    ) -> None:\n",
        "        super().__init__(**kwargs)\n",
        "        self.policy_retriever = policy_retriever\n",
        "        self.llm = llm or OpenAI(model=\"gpt-4o\")\n",
        "\n",
        "    @step\n",
        "    async def load_claim_info(self, ctx: Context, ev: StartEvent) -> ClaimInfoEvent:\n",
        "        if self._verbose:\n",
        "            ctx.write_event_to_stream(LogEvent(msg=\">> Loading Claim Info\"))\n",
        "        claim_info = parse_claim(ev.claim_json_path)\n",
        "        await ctx.set(\"claim_info\", claim_info)\n",
        "        return ClaimInfoEvent(claim_info=claim_info)\n",
        "\n",
        "    @step\n",
        "    async def generate_policy_queries(self, ctx: Context, ev: ClaimInfoEvent) -> PolicyQueryEvent:\n",
        "        if self._verbose:\n",
        "            ctx.write_event_to_stream(LogEvent(msg=\">> Generating Policy Queries\"))\n",
        "        prompt = ChatPromptTemplate.from_messages([(\"user\", GENERATE_POLICY_QUERIES_PROMPT)])\n",
        "        queries = await self.llm.astructured_predict(\n",
        "            PolicyQueries,\n",
        "            prompt,\n",
        "            claim_info=ev.claim_info.model_dump_json()\n",
        "        )\n",
        "        return PolicyQueryEvent(queries=queries)\n",
        "\n",
        "    @step\n",
        "    async def retrieve_policy_text(self, ctx: Context, ev: PolicyQueryEvent) -> PolicyMatchedEvent:\n",
        "        if self._verbose:\n",
        "            ctx.write_event_to_stream(LogEvent(msg=\">> Retrieving policy sections\"))\n",
        "\n",
        "        claim_info = await ctx.get(\"claim_info\")\n",
        "\n",
        "        combined_docs = {}\n",
        "        for query in ev.queries.queries:\n",
        "            if self._verbose:\n",
        "                ctx.write_event_to_stream(LogEvent(msg=f\">> Query: {query}\"))\n",
        "            # fetch policy text\n",
        "            docs = await self.policy_retriever.aretrieve(query)\n",
        "            for d in docs:\n",
        "                combined_docs[d.id_] = d\n",
        "\n",
        "        # also fetch the declarations page for the policy holder\n",
        "        d_doc = get_declarations_docs(claim_info.policy_number)[0]\n",
        "        combined_docs[d_doc.id_] = d_doc\n",
        "\n",
        "        policy_text = \"\\n\\n\".join([doc.get_content() for doc in combined_docs.values()])\n",
        "        await ctx.set(\"policy_text\", policy_text)\n",
        "        return PolicyMatchedEvent(policy_text=policy_text)\n",
        "\n",
        "    @step\n",
        "    async def generate_recommendation(self, ctx: Context, ev: PolicyMatchedEvent) -> RecommendationEvent:\n",
        "        if self._verbose:\n",
        "            ctx.write_event_to_stream(LogEvent(msg=\">> Generating Policy Recommendation\"))\n",
        "        claim_info = await ctx.get(\"claim_info\")\n",
        "        prompt = ChatPromptTemplate.from_messages([(\"user\", POLICY_RECOMMENDATION_PROMPT)])\n",
        "        recommendation = await self.llm.astructured_predict(\n",
        "            PolicyRecommendation,\n",
        "            prompt,\n",
        "            claim_info=claim_info.model_dump_json(),\n",
        "            policy_text=ev.policy_text\n",
        "        )\n",
        "        if self._verbose:\n",
        "            ctx.write_event_to_stream(LogEvent(msg=f\">> Recommendation: {recommendation.model_dump_json()}\"))\n",
        "        return RecommendationEvent(recommendation=recommendation)\n",
        "\n",
        "    @step\n",
        "    async def finalize_decision(self, ctx: Context, ev: RecommendationEvent) -> DecisionEvent:\n",
        "        if self._verbose:\n",
        "            ctx.write_event_to_stream(LogEvent(msg=\">> Finalizing Decision\"))\n",
        "        claim_info = await ctx.get(\"claim_info\")\n",
        "        rec = ev.recommendation\n",
        "        covered = \"covered\" in rec.recommendation_summary.lower() or (rec.settlement_amount is not None and rec.settlement_amount > 0)\n",
        "        deductible = rec.deductible if rec.deductible is not None else 0.0\n",
        "        recommended_payout = rec.settlement_amount if rec.settlement_amount else 0.0\n",
        "        decision = ClaimDecision(\n",
        "            claim_number=claim_info.claim_number,\n",
        "            covered=covered,\n",
        "            deductible=deductible,\n",
        "            recommended_payout=recommended_payout,\n",
        "            notes=rec.recommendation_summary\n",
        "        )\n",
        "        return DecisionEvent(decision=decision)\n",
        "\n",
        "    @step\n",
        "    async def output_result(self, ctx: Context, ev: DecisionEvent) -> StopEvent:\n",
        "        if self._verbose:\n",
        "            ctx.write_event_to_stream(LogEvent(msg=f\">> Decision: {ev.decision.model_dump_json()}\"))\n",
        "        return StopEvent(result={\"decision\": ev.decision})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8557f4a7-ce61-4757-8f35-6785574c57cb",
      "metadata": {
        "id": "8557f4a7-ce61-4757-8f35-6785574c57cb"
      },
      "outputs": [],
      "source": [
        "from llama_index.llms.openai import OpenAI\n",
        "\n",
        "llm = OpenAI(model=\"gpt-4o\")\n",
        "workflow = AutoInsuranceWorkflow(\n",
        "    policy_retriever=retriever,\n",
        "    llm=llm,\n",
        "    verbose=True,\n",
        "    timeout=None,  # don't worry about timeout to make sure it completes\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66d79ab2-1455-4f8f-bde3-8bbd51b7da51",
      "metadata": {
        "id": "66d79ab2-1455-4f8f-bde3-8bbd51b7da51"
      },
      "source": [
        "#### Visualize the workflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "470f298b-c3a3-485e-a440-b0576e45134d",
      "metadata": {
        "id": "470f298b-c3a3-485e-a440-b0576e45134d",
        "outputId": "581d354a-5068-41df-bdde-fd242a55691b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'NoneType'>\n",
            "<class '__main__.DecisionEvent'>\n",
            "<class '__main__.PolicyQueryEvent'>\n",
            "<class '__main__.RecommendationEvent'>\n",
            "<class '__main__.ClaimInfoEvent'>\n",
            "<class 'llama_index.core.workflow.events.StopEvent'>\n",
            "<class '__main__.PolicyMatchedEvent'>\n",
            "auto_insurance_workflow.html\n"
          ]
        }
      ],
      "source": [
        "from llama_index.utils.workflow import draw_all_possible_flows\n",
        "\n",
        "draw_all_possible_flows(AutoInsuranceWorkflow, filename=\"auto_insurance_workflow.html\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f11484c-52b8-424f-9a64-7456068ff1b1",
      "metadata": {
        "id": "0f11484c-52b8-424f-9a64-7456068ff1b1"
      },
      "source": [
        "## Run the Workflow\n",
        "\n",
        "Let's run the full workflow and generate the output!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9a55b1b-8263-4365-b187-6204150ec4cb",
      "metadata": {
        "scrolled": true,
        "id": "b9a55b1b-8263-4365-b187-6204150ec4cb",
        "outputId": "367ecefc-0a31-4624-f9c5-6d648344bc86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running step load_claim_info\n",
            "Step load_claim_info produced event ClaimInfoEvent\n",
            ">> Loading Claim Info\n",
            "Running step generate_policy_queries\n",
            ">> Generating Policy Queries\n",
            "Step generate_policy_queries produced event PolicyQueryEvent\n",
            "Running step retrieve_policy_text\n",
            ">> Retrieving policy sections\n",
            ">> Query: Collision coverage conditions for POLICY-ABC123\n",
            ">> Query: Deductible application for rear-end collision under POLICY-ABC123\n",
            ">> Query: Special endorsements for rear-end collisions in POLICY-ABC123\n",
            ">> Query: No-fault coverage details in POLICY-ABC123\n",
            ">> Query: Repair cost coverage limits for POLICY-ABC123\n",
            "Step retrieve_policy_text produced event PolicyMatchedEvent\n",
            "Running step generate_recommendation\n",
            ">> Generating Policy Recommendation\n",
            "Step generate_recommendation produced event RecommendationEvent\n",
            ">> Recommendation: {\"policy_section\":\"PART D COVERAGE FOR DAMAGE TO YOUR AUTO - INSURING AGREEMENT - COLLISION\",\"recommendation_summary\":\"The collision is not covered due to the exclusion for carrying property for compensation, such as delivering pizzas.\",\"deductible\":500.0,\"settlement_amount\":0.0}\n",
            "Running step finalize_decision\n",
            "Step finalize_decision produced event DecisionEvent\n",
            "Running step output_result\n",
            "Step output_result produced event StopEvent\n",
            ">> Finalizing Decision\n",
            ">> Decision: {\"claim_number\":\"CLAIM-0001\",\"covered\":true,\"deductible\":500.0,\"recommended_payout\":0.0,\"notes\":\"The collision is not covered due to the exclusion for carrying property for compensation, such as delivering pizzas.\"}\n",
            "claim_number='CLAIM-0001' covered=True deductible=500.0 recommended_payout=0.0 notes='The collision is not covered due to the exclusion for carrying property for compensation, such as delivering pizzas.'\n"
          ]
        }
      ],
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "async def stream_workflow(workflow, **workflow_kwargs):\n",
        "    handler = workflow.run(**workflow_kwargs)\n",
        "    async for event in handler.stream_events():\n",
        "        if isinstance(event, LogEvent):\n",
        "            if event.delta:\n",
        "                print(event.msg, end=\"\")\n",
        "            else:\n",
        "                print(event.msg)\n",
        "\n",
        "    return await handler\n",
        "\n",
        "\n",
        "response_dict = await stream_workflow(workflow, claim_json_path=\"data/john.json\")\n",
        "print(str(response_dict[\"decision\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "710ae172-b7e7-4d95-960f-f9cd90b40e3f",
      "metadata": {
        "id": "710ae172-b7e7-4d95-960f-f9cd90b40e3f",
        "outputId": "f686614f-e4e5-4ef3-e359-e8ddc60d2eae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running step load_claim_info\n",
            "Step load_claim_info produced event ClaimInfoEvent\n",
            ">> Loading Claim Info\n",
            "Running step generate_policy_queries\n",
            ">> Generating Policy Queries\n",
            "Step generate_policy_queries produced event PolicyQueryEvent\n",
            "Running step retrieve_policy_text\n",
            ">> Retrieving policy sections\n",
            ">> Query: Collision coverage conditions for rear-end collisions\n",
            ">> Query: Deductible application for rear-end collision claims\n",
            ">> Query: Special endorsements related to rear-end collisions\n",
            ">> Query: No-fault scenario coverage for rear-end collisions\n",
            ">> Query: Policy clauses for repair cost coverage in rear-end collisions\n",
            "Step retrieve_policy_text produced event PolicyMatchedEvent\n",
            "Running step generate_recommendation\n",
            ">> Generating Policy Recommendation\n",
            "Step generate_recommendation produced event RecommendationEvent\n",
            ">> Recommendation: {\"policy_section\":\"PART D COVERAGE FOR DAMAGE TO YOUR AUTO - INSURING AGREEMENT - COLLISION\",\"recommendation_summary\":\"The collision is covered under Part D - Coverage for Damage to Your Auto, as the insured has Collision coverage with a $500 deductible. The estimated repair cost is $2,200, so the recommended settlement amount is $1,700 after applying the deductible.\",\"deductible\":500.0,\"settlement_amount\":1700.0}\n",
            "Running step finalize_decision\n",
            "Step finalize_decision produced event DecisionEvent\n",
            "Running step output_result\n",
            "Step output_result produced event StopEvent\n",
            ">> Finalizing Decision\n",
            ">> Decision: {\"claim_number\":\"CLAIM-0002\",\"covered\":true,\"deductible\":500.0,\"recommended_payout\":1700.0,\"notes\":\"The collision is covered under Part D - Coverage for Damage to Your Auto, as the insured has Collision coverage with a $500 deductible. The estimated repair cost is $2,200, so the recommended settlement amount is $1,700 after applying the deductible.\"}\n",
            "claim_number='CLAIM-0002' covered=True deductible=500.0 recommended_payout=1700.0 notes='The collision is covered under Part D - Coverage for Damage to Your Auto, as the insured has Collision coverage with a $500 deductible. The estimated repair cost is $2,200, so the recommended settlement amount is $1,700 after applying the deductible.'\n"
          ]
        }
      ],
      "source": [
        "response_dict = await stream_workflow(workflow, claim_json_path=\"data/alice.json\")\n",
        "print(str(response_dict[\"decision\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cbd782a-e6f7-4ca9-88df-cf74a1116eb1",
      "metadata": {
        "id": "1cbd782a-e6f7-4ca9-88df-cf74a1116eb1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "llamacloud-demo",
      "language": "python",
      "name": "llamacloud-demo"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}